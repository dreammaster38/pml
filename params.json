{"name":"Pml","tagline":"This repository is for the Coursera Practical Machine Learning course","body":"PML - Programming Assignment\r\n========================================================\r\n\r\nThis Coursera course teaches us about Practical Machine Learning with R.\r\nWe get a good knowledge about various Machine Learning algorithms and useful R packages to made a Data Scientist's day more comfortable. This assessment should show what we have learned so far.\r\n\r\n# Abstract\r\n---------------\r\n\r\nQuantified Self movement is currently a new trend to improve personal or professional productivity in health and wellness. As discribed in Wikipedia, people have abelities to track physical activity, caloric intake, sleep quality, posture, and other factors involved in personal well-being.\r\nTo measure themselves various sensors will be used to collect specific data.\r\n\r\nOur goal for this assignment will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).\r\n\r\nTo accomplish this assignment we have to predict the manner in which they did the exercise. This is the \"classe\" variable in the training set.\r\n\r\n### Important points are:\r\n\r\n* how we used cross validation\r\n* what is the expected out of sample error\r\n* why we made the choices you did\r\n* predict 20 given different test cases\r\n* a good accuracy\r\n\r\n### Minor points are:\r\n\r\n* performance\r\n* scalability\r\n\r\nI have devided my approach into different steps. I will subscribe each step as good as i can.\r\n\r\n## Requirements\r\nLoad all necessary libraries used for this project\r\n\r\n```r\r\nlibrary(caret)\r\n```\r\n\r\n```\r\n## Loading required package: lattice\r\n## Loading required package: ggplot2\r\n```\r\n\r\n```r\r\nlibrary(randomForest)\r\n```\r\n\r\n```\r\n## randomForest 4.6-7\r\n## Type rfNews() to see new features/changes/bug fixes.\r\n```\r\n\r\n```r\r\nlibrary(e1071)\r\nlibrary(doParallel)\r\n```\r\n\r\n```\r\n## Loading required package: foreach\r\n## Loading required package: iterators\r\n## Loading required package: parallel\r\n```\r\n\r\n## Step 1: Loading data\r\nLoad the data sets and replace unuseful strings with NAs.\r\n\r\n```r\r\ntrainRawData <- read.csv(\"data/pml-training.csv\", na.strings=c(\"NA\",\"\", \"#DIV/0!\"))\r\ntestingRawData <- read.csv(\"data/pml-testing.csv\", na.strings=c(\"NA\",\"\", \"#DIV/0!\"))\r\n```\r\n\r\n## Step 2: Cleaning up the data\r\n\r\nFind columns with NAs set and remove them. This will remove columns which could be imputed too.\r\nI made this as a comromise to speed things up.\r\n\r\n```r\r\nset.seed(1972)\r\ncleanedData <- trainRawData[ ,colSums(is.na(trainRawData)) == 0]\r\ntesting <- testingRawData[ ,colSums(is.na(trainRawData)) == 0]\r\n```\r\n\r\nCreate a training and cross validation set as shown in the videos.\r\nSo we get 70% out of the data for training and 30% for crossvalidation\r\n\r\n```r\r\ntrainIndex <- createDataPartition(y = cleanedData$classe, p=0.7, list=FALSE) # 3927 rows\r\ntraining <- cleanedData[trainIndex,]\r\ncross <- cleanedData[-trainIndex,]\r\n```\r\n\r\nDiscard unuseful predictors because they are not numeric.\r\n\r\n```r\r\ncolumnsToRemove <- names(training) %in% c(\"raw_timestamp_part_1\", \"raw_timestamp_part_2\", \"cvtd_timestamp\", \"X\", \"user_name\", \"new_window\")\r\ntraining <- training[ , !columnsToRemove]\r\ncross <- cross[ , !columnsToRemove]\r\ntesting <- testing[, !columnsToRemove]\r\n```\r\n\r\nThe cleanup step gaves us 53 predictors to work with.\r\n\r\n### Skewness\r\nLets have a look at the skewness of the data. To find it out we use the skewness function of the 'e1071' package.\r\n\r\n```r\r\n# check data for skewness\r\nclasseName <- names(training) %in% c(\"classe\") \r\ntestForSkewness <- training[!classeName]\r\n# apply the skewnes function to each numeric column of our training set\r\nskewValues <- apply(testForSkewness, 2, skewness)\r\n# create a data frame for fancier printing\r\nskewValuesDf <- data.frame(skewValues)\r\nprint(skewValuesDf)\r\n```\r\n\r\n```\r\n##                      skewValues\r\n## num_window            2.310e-02\r\n## roll_belt            -2.050e-03\r\n## pitch_belt           -9.953e-01\r\n## yaw_belt              9.106e-01\r\n## total_accel_belt      4.702e-02\r\n## gyros_belt_x         -5.977e-01\r\n## gyros_belt_y         -6.394e-02\r\n## gyros_belt_z          2.113e-01\r\n## accel_belt_x          9.646e-01\r\n## accel_belt_y          1.767e-01\r\n## accel_belt_z          6.569e-03\r\n## magnet_belt_x         1.429e+00\r\n## magnet_belt_y        -2.229e+00\r\n## magnet_belt_z         2.631e-01\r\n## roll_arm             -1.816e-01\r\n## pitch_arm             1.956e-01\r\n## yaw_arm              -8.960e-02\r\n## total_accel_arm       7.324e-02\r\n## gyros_arm_x          -2.953e-01\r\n## gyros_arm_y           1.179e-01\r\n## gyros_arm_z          -1.644e-01\r\n## accel_arm_x           3.521e-01\r\n## accel_arm_y           8.161e-02\r\n## accel_arm_z          -8.565e-01\r\n## magnet_arm_x         -1.513e-01\r\n## magnet_arm_y         -4.653e-01\r\n## magnet_arm_z         -1.146e+00\r\n## roll_dumbbell        -7.509e-01\r\n## pitch_dumbbell        5.359e-01\r\n## yaw_dumbbell          2.237e-01\r\n## total_accel_dumbbell  5.896e-01\r\n## gyros_dumbbell_x     -1.089e+02\r\n## gyros_dumbbell_y      3.587e+01\r\n## gyros_dumbbell_z      1.148e+02\r\n## accel_dumbbell_x     -4.547e-01\r\n## accel_dumbbell_y      3.438e-01\r\n## accel_dumbbell_z     -7.782e-02\r\n## magnet_dumbbell_x     1.714e+00\r\n## magnet_dumbbell_y    -1.862e+00\r\n## magnet_dumbbell_z     8.682e-01\r\n## roll_forearm         -4.631e-01\r\n## pitch_forearm        -5.278e-01\r\n## yaw_forearm          -2.664e-01\r\n## total_accel_forearm  -5.693e-01\r\n## gyros_forearm_x      -2.683e+00\r\n## gyros_forearm_y       5.417e+01\r\n## gyros_forearm_z       1.024e+02\r\n## accel_forearm_x      -2.375e-01\r\n## accel_forearm_y      -6.435e-01\r\n## accel_forearm_z       4.371e-01\r\n## magnet_forearm_x      6.327e-01\r\n## magnet_forearm_y     -7.478e-01\r\n## magnet_forearm_z     -1.216e+00\r\n```\r\n\r\n```r\r\n# plot a histogram of the skewness.\r\nhist(skewValues, col=heat.colors(17), xlab=\"Skewness of all predictors\", breaks=20)\r\n```\r\n\r\n![plot of chunk unnamed-chunk-6](figure/unnamed-chunk-6.png) \r\n\r\nAs you can see we have left-skewness and also right-skewness in our data set. So we need some pre-processing prior to fit our model.\r\nThis step will be done directly in the preProcess step of caret's train function.\r\n\r\n## Step 3 Model creation\r\n\r\nI've trained a Random Forest with 10 K-Folds cross validation partitions in the train control parameter to accomplish this ask.\r\nThere was a pre processing step added to normalize the data because it's are skewed as showed above. I've used center and scale to normalize it.\r\n\r\n### Build a Random Forest (RF)\r\n\r\n#### Advantages of RF:\r\n* very simple to use even with default settings\r\n* produces mostly results with good accuracy without special tuning parameters\r\n* robust\r\n* fast\r\n* can handle larger problems before slowing\r\n\r\n#### Disadvantages of RF\r\n* difficult to interpret\r\n\r\nFurther i've used the doParallel package to speed things up little bit\r\n\r\n\r\n```r\r\n# Create clusters for all available cores communicating over sockets\r\ncl <- makeCluster(detectCores() / 2)\r\nregisterDoParallel(cl)\r\n\r\n# global settings used for for all models\r\n#ctrl <- trainControl(method='cv', number=10, savePred=T, classProb=T, verboseIter=T)\r\nctrl <- trainControl(method='cv', number=10, allowParallel=TRUE)\r\n```\r\n\r\nBuild a fitted Random Forest model with normalization, and 10-Fold cross vaidation\r\n\r\n\r\n```r\r\nmodFitRf <- train(training$classe ~.,\r\n                data = training,\r\n                do.trace=100,\r\n                method=\"rf\",\r\n                trControl=ctrl,\r\n                preProcess=(method=c(\"center\", \"scale\")))\r\n```\r\n\r\n```\r\n## ntree      OOB      1      2      3      4      5\r\n##   100:   0.26%  0.03%  0.53%  0.25%  0.40%  0.24%\r\n##   200:   0.25%  0.05%  0.53%  0.25%  0.36%  0.20%\r\n##   300:   0.25%  0.05%  0.45%  0.25%  0.36%  0.24%\r\n##   400:   0.23%  0.05%  0.41%  0.25%  0.31%  0.24%\r\n##   500:   0.24%  0.05%  0.38%  0.33%  0.31%  0.24%\r\n```\r\n\r\n## Results\r\n\r\n### Out of Sample accuracy, Random Forest\r\n\r\nNow let's take a look at our generated model and it's statistics which looks like as follows:\r\n\r\n\r\n```r\r\nprint(modFitRf)\r\n```\r\n\r\n```\r\n## Random Forest \r\n## \r\n## 13737 samples\r\n##    53 predictors\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## Pre-processing: centered, scaled \r\n## Resampling: Cross-Validated (10 fold) \r\n## \r\n## Summary of sample sizes: 12362, 12364, 12363, 12363, 12364, 12363, ... \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD\r\n##   2     1         1      0.003        0.003   \r\n##   30    1         1      0.002        0.002   \r\n##   50    1         1      0.002        0.003   \r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 27.\r\n```\r\n\r\n```r\r\nprint(modFitRf$finalModel)\r\n```\r\n\r\n```\r\n## \r\n## Call:\r\n##  randomForest(x = x, y = y, mtry = param$mtry, do.trace = 100) \r\n##                Type of random forest: classification\r\n##                      Number of trees: 500\r\n## No. of variables tried at each split: 27\r\n## \r\n##         OOB estimate of  error rate: 0.24%\r\n## Confusion matrix:\r\n##      A    B    C    D    E class.error\r\n## A 3904    1    0    0    1    0.000512\r\n## B    7 2648    3    0    0    0.003762\r\n## C    0    8 2388    0    0    0.003339\r\n## D    0    0    6 2245    1    0.003108\r\n## E    0    1    0    5 2519    0.002376\r\n```\r\n\r\nAs you can see the OOB error is ~0.25%. This is a good result.\r\n\r\nPredict against our cross validation set created in step 2 to find out the accuracy of our model.\r\n\r\n```r\r\npredCrossRf <- predict(modFitRf, cross)\r\nprint(confusionMatrix(predCrossRf, cross$classe))\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1674    1    0    0    0\r\n##          B    0 1137    6    0    0\r\n##          C    0    1 1020    5    0\r\n##          D    0    0    0  959    0\r\n##          E    0    0    0    0 1082\r\n## \r\n## Overall Statistics\r\n##                                         \r\n##                Accuracy : 0.998         \r\n##                  95% CI : (0.996, 0.999)\r\n##     No Information Rate : 0.284         \r\n##     P-Value [Acc > NIR] : <2e-16        \r\n##                                         \r\n##                   Kappa : 0.997         \r\n##  Mcnemar's Test P-Value : NA            \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity             1.000    0.998    0.994    0.995    1.000\r\n## Specificity             1.000    0.999    0.999    1.000    1.000\r\n## Pos Pred Value          0.999    0.995    0.994    1.000    1.000\r\n## Neg Pred Value          1.000    1.000    0.999    0.999    1.000\r\n## Prevalence              0.284    0.194    0.174    0.164    0.184\r\n## Detection Rate          0.284    0.193    0.173    0.163    0.184\r\n## Detection Prevalence    0.285    0.194    0.174    0.163    0.184\r\n## Balanced Accuracy       1.000    0.998    0.996    0.997    1.000\r\n```\r\n\r\nThe confusionMatrix shows us that we have an accuracy of 99.8% with our cross validation set, This is a pretty good result that fits our needs.\r\n\r\nThe accuracy is good enough to predict the test data set against our Random Forest model.\r\n\r\n\r\nPrint the overall agreement and Kappa:\r\n\r\n```r\r\naccuracySummary <- postResample(predCrossRf, cross$classe)\r\nprint(accuracySummary)\r\n```\r\n\r\n```\r\n## Accuracy    Kappa \r\n##   0.9978   0.9972\r\n```\r\n\r\n\r\n## Step 4: Submitted prediction results on the supplied test set \r\n\r\nThis is my final result of the prediction that i submitted with my 53 predictors:\r\n\r\n```r\r\npredRf <- predict(modFitRf, testing)\r\nprint(predRf)\r\n```\r\n\r\n```\r\n##  [1] B A B A A E D B A A B C B A E E A B B B\r\n## Levels: A B C D E\r\n```\r\n\r\n```r\r\n# stop all created cluster nodes\r\nstopCluster(cl)\r\n```\r\n\r\n## FInal words\r\n\r\nI tried to train a Polymomial SVM too, so i can compare two models to each other. Unfortunately it runs a couple of hours and it was not possible for me to build this final document with both models trained via knitr again and again.\r\nIt tooks me many, many time to accomplish this task nevertheless i had a lot of fun to play with ML technology.\r\n\r\n## References\r\n\r\n[1]: http://groupware.les.inf.puc-rio.br/har, Data sets for Human Activity Recognition\r\n\r\n[2]: Albert A. Montillo, Ph.D., Guest lecture: Statistical Foundations of Data Analysis\r\nTemple University 4-2-2009, http://www.dabi.temple.edu/~hbling/8590.002/Montillo_RandomForests_4-2-2009.pdf\r\n\r\n[3]: Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.\r\n\r\n[4]: Kuhn, M.; Johnson, K. Applied Predictive Modeing, Springer 2013","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}